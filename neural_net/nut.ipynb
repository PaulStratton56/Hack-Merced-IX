{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from network import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the data\n",
    "data = pd.read_csv('diabetes_clean_2015.csv')\n",
    "target ='DIABETE3'\n",
    "X = data.drop(columns=[target, \"_DRNKWEK\"])  # Input features\n",
    "Y = data[target]    # Target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            try:\n",
    "                output = model(data)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during forward pass: {e}\")\n",
    "                return 0\n",
    "            try:\n",
    "                loss = loss_func(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during backward pass: {e}\")\n",
    "                return 1\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/batch_idx}')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of batches in train_loader: 828\n",
      "Number of batches in test_loader: 207\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Move the model and data to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = network().to(device)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.to_numpy(), np.expand_dims(Y.to_numpy(),axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Number of batches in train_loader:\", len(train_loader))\n",
    "print(\"Number of batches in test_loader:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.6959252683254367\n",
      "Epoch [2/500], Loss: 0.6940327763124994\n",
      "Epoch [3/500], Loss: 0.6940035279457342\n",
      "Epoch [4/500], Loss: 0.6939944926167342\n",
      "Epoch [5/500], Loss: 0.6939905120787339\n",
      "Epoch [6/500], Loss: 0.6939884453038927\n",
      "Epoch [7/500], Loss: 0.6939872736798233\n",
      "Epoch [8/500], Loss: 0.6939865615232391\n",
      "Epoch [9/500], Loss: 0.6939861266327596\n",
      "Epoch [10/500], Loss: 0.6939858352402822\n",
      "Epoch [11/500], Loss: 0.6939856676697875\n",
      "Epoch [12/500], Loss: 0.6939855450730514\n",
      "Epoch [13/500], Loss: 0.6939854693960538\n",
      "Epoch [14/500], Loss: 0.6939854452514879\n",
      "Epoch [15/500], Loss: 0.6939853674843637\n",
      "Epoch [16/500], Loss: 0.6939853289251317\n",
      "Epoch [17/500], Loss: 0.6939853289251317\n",
      "Epoch [18/500], Loss: 0.6939853289251317\n",
      "Epoch [19/500], Loss: 0.6939853289251317\n",
      "Epoch [20/500], Loss: 0.6939853289251317\n",
      "Epoch [21/500], Loss: 0.6939853289251317\n",
      "Epoch [22/500], Loss: 0.6939853289251317\n",
      "Epoch [23/500], Loss: 0.6939853289251317\n",
      "Epoch [24/500], Loss: 0.6939853289251317\n",
      "Epoch [25/500], Loss: 0.6939853289251317\n",
      "Epoch [26/500], Loss: 0.6939853289251317\n",
      "Epoch [27/500], Loss: 0.6939853289251317\n",
      "Epoch [28/500], Loss: 0.6939853289251317\n",
      "Epoch [29/500], Loss: 0.6939853289251317\n",
      "Epoch [30/500], Loss: 0.6939853289251317\n",
      "Epoch [31/500], Loss: 0.6939853289251317\n",
      "Epoch [32/500], Loss: 0.6939853289251317\n",
      "Epoch [33/500], Loss: 0.6939853289251317\n",
      "Epoch [34/500], Loss: 0.6939853289251317\n",
      "Epoch [35/500], Loss: 0.6939853289251317\n",
      "Epoch [36/500], Loss: 0.6939853289251317\n",
      "Epoch [37/500], Loss: 0.6939853289251317\n",
      "Epoch [38/500], Loss: 0.6939853289251317\n",
      "Epoch [39/500], Loss: 0.6939853289251317\n",
      "Epoch [40/500], Loss: 0.6939853289251317\n",
      "Epoch [41/500], Loss: 0.6939853289251317\n",
      "Epoch [42/500], Loss: 0.6939853289251317\n",
      "Epoch [43/500], Loss: 0.6939853289251317\n",
      "Epoch [44/500], Loss: 0.6939853289251317\n",
      "Epoch [45/500], Loss: 0.6939853289251317\n",
      "Epoch [46/500], Loss: 0.6939853289251317\n",
      "Epoch [47/500], Loss: 0.6939853289251317\n",
      "Epoch [48/500], Loss: 0.6939853289251317\n",
      "Epoch [49/500], Loss: 0.6939853289251317\n",
      "Epoch [50/500], Loss: 0.6939853289251317\n",
      "Epoch [51/500], Loss: 0.6939853289251317\n",
      "Epoch [52/500], Loss: 0.6939853289251317\n",
      "Epoch [53/500], Loss: 0.6939853289251317\n",
      "Epoch [54/500], Loss: 0.6939853289251317\n",
      "Epoch [55/500], Loss: 0.6939853289251317\n",
      "Epoch [56/500], Loss: 0.6939853289251317\n",
      "Epoch [57/500], Loss: 0.6939853289251317\n",
      "Epoch [58/500], Loss: 0.6939853289251317\n",
      "Epoch [59/500], Loss: 0.6939853289251317\n",
      "Epoch [60/500], Loss: 0.6939853289251317\n",
      "Epoch [61/500], Loss: 0.6939853289251317\n",
      "Epoch [62/500], Loss: 0.6939853289251317\n",
      "Epoch [63/500], Loss: 0.6939853289251317\n",
      "Epoch [64/500], Loss: 0.6939853289251317\n",
      "Epoch [65/500], Loss: 0.6939853289251317\n",
      "Epoch [66/500], Loss: 0.6939853289251317\n",
      "Epoch [67/500], Loss: 0.6939853289251317\n",
      "Epoch [68/500], Loss: 0.6939853289251317\n",
      "Epoch [69/500], Loss: 0.6939853289251317\n",
      "Epoch [70/500], Loss: 0.6939853289251317\n",
      "Epoch [71/500], Loss: 0.6939853289251317\n",
      "Epoch [72/500], Loss: 0.6939853289251317\n",
      "Epoch [73/500], Loss: 0.6939853289251317\n",
      "Epoch [74/500], Loss: 0.6939853289251317\n",
      "Epoch [75/500], Loss: 0.6939853289251317\n",
      "Epoch [76/500], Loss: 0.6939853289251317\n",
      "Epoch [77/500], Loss: 0.6939853289251317\n",
      "Epoch [78/500], Loss: 0.6939853289251317\n",
      "Epoch [79/500], Loss: 0.6939853289251317\n",
      "Epoch [80/500], Loss: 0.6939853289251317\n",
      "Epoch [81/500], Loss: 0.6939853289251317\n",
      "Epoch [82/500], Loss: 0.6939853289251317\n",
      "Epoch [83/500], Loss: 0.6939853289251317\n",
      "Epoch [84/500], Loss: 0.6939853289251317\n",
      "Epoch [85/500], Loss: 0.6939853289251317\n",
      "Epoch [86/500], Loss: 0.6939853289251317\n",
      "Epoch [87/500], Loss: 0.6939853289251317\n",
      "Epoch [88/500], Loss: 0.6939853289251317\n",
      "Epoch [89/500], Loss: 0.6939853289251317\n",
      "Epoch [90/500], Loss: 0.6939853289251317\n",
      "Epoch [91/500], Loss: 0.6939853289251317\n",
      "Epoch [92/500], Loss: 0.6939853289251317\n",
      "Epoch [93/500], Loss: 0.6939853289251317\n",
      "Epoch [94/500], Loss: 0.6939853289251317\n",
      "Epoch [95/500], Loss: 0.6939853289251317\n",
      "Epoch [96/500], Loss: 0.6939853289251317\n",
      "Epoch [97/500], Loss: 0.6939853289251317\n",
      "Epoch [98/500], Loss: 0.6939853289251317\n",
      "Epoch [99/500], Loss: 0.6939853289251317\n",
      "Epoch [100/500], Loss: 0.6939853289251317\n",
      "Epoch [101/500], Loss: 0.6939853289251317\n",
      "Epoch [102/500], Loss: 0.6939853289251317\n",
      "Epoch [103/500], Loss: 0.6939853289251317\n",
      "Epoch [104/500], Loss: 0.6939853289251317\n",
      "Epoch [105/500], Loss: 0.6939853289251317\n",
      "Epoch [106/500], Loss: 0.6939853289251317\n",
      "Epoch [107/500], Loss: 0.6939853289251317\n",
      "Epoch [108/500], Loss: 0.6939853289251317\n",
      "Epoch [109/500], Loss: 0.6939853289251317\n",
      "Epoch [110/500], Loss: 0.6939853289251317\n",
      "Epoch [111/500], Loss: 0.6939853289251317\n",
      "Epoch [112/500], Loss: 0.6939853289251317\n",
      "Epoch [113/500], Loss: 0.6939853289251317\n",
      "Epoch [114/500], Loss: 0.6939853289251317\n",
      "Epoch [115/500], Loss: 0.6939853289251317\n",
      "Epoch [116/500], Loss: 0.6939853289251317\n",
      "Epoch [117/500], Loss: 0.6939853289251317\n",
      "Epoch [118/500], Loss: 0.6939853289251317\n",
      "Epoch [119/500], Loss: 0.6939853289251317\n",
      "Epoch [120/500], Loss: 0.6939853289251317\n",
      "Epoch [121/500], Loss: 0.6939853289251317\n",
      "Epoch [122/500], Loss: 0.6939853289251317\n",
      "Epoch [123/500], Loss: 0.6939853289251317\n",
      "Epoch [124/500], Loss: 0.6939853289251317\n",
      "Epoch [125/500], Loss: 0.6939853289251317\n",
      "Epoch [126/500], Loss: 0.6939853289251317\n",
      "Epoch [127/500], Loss: 0.6939853289251317\n",
      "Epoch [128/500], Loss: 0.6939853289251317\n",
      "Epoch [129/500], Loss: 0.6939853289251317\n",
      "Epoch [130/500], Loss: 0.6939853289251317\n",
      "Epoch [131/500], Loss: 0.6939853289251317\n",
      "Epoch [132/500], Loss: 0.6939853289251317\n",
      "Epoch [133/500], Loss: 0.6939853289251317\n",
      "Epoch [134/500], Loss: 0.6939853289251317\n",
      "Epoch [135/500], Loss: 0.6939853289251317\n",
      "Epoch [136/500], Loss: 0.6939853289251317\n",
      "Epoch [137/500], Loss: 0.6939853289251317\n",
      "Epoch [138/500], Loss: 0.6939853289251317\n",
      "Epoch [139/500], Loss: 0.6939853289251317\n",
      "Epoch [140/500], Loss: 0.6939853289251317\n",
      "Epoch [141/500], Loss: 0.6939853289251317\n",
      "Epoch [142/500], Loss: 0.6939853289251317\n",
      "Epoch [143/500], Loss: 0.6939853289251317\n",
      "Epoch [144/500], Loss: 0.6939853289251317\n",
      "Epoch [145/500], Loss: 0.6939853289251317\n",
      "Epoch [146/500], Loss: 0.6939853289251317\n",
      "Epoch [147/500], Loss: 0.6939853289251317\n",
      "Epoch [148/500], Loss: 0.6939853289251317\n",
      "Epoch [149/500], Loss: 0.6939853289251317\n",
      "Epoch [150/500], Loss: 0.6939853289251317\n",
      "Epoch [151/500], Loss: 0.6939853289251317\n",
      "Epoch [152/500], Loss: 0.6939853289251317\n",
      "Epoch [153/500], Loss: 0.6939853289251317\n",
      "Epoch [154/500], Loss: 0.6939853289251317\n",
      "Epoch [155/500], Loss: 0.6939853289251317\n",
      "Epoch [156/500], Loss: 0.6939853289251317\n",
      "Epoch [157/500], Loss: 0.6939853289251317\n",
      "Epoch [158/500], Loss: 0.6939853289251317\n",
      "Epoch [159/500], Loss: 0.6939853289251317\n",
      "Epoch [160/500], Loss: 0.6939853289251317\n",
      "Epoch [161/500], Loss: 0.6939853289251317\n",
      "Epoch [162/500], Loss: 0.6939853289251317\n",
      "Epoch [163/500], Loss: 0.6939853289251317\n",
      "Epoch [164/500], Loss: 0.6939853289251317\n",
      "Epoch [165/500], Loss: 0.6939853289251317\n",
      "Epoch [166/500], Loss: 0.6939853289251317\n",
      "Epoch [167/500], Loss: 0.6939853289251317\n",
      "Epoch [168/500], Loss: 0.6939853289251317\n",
      "Epoch [169/500], Loss: 0.6939853289251317\n",
      "Epoch [170/500], Loss: 0.6939853289251317\n",
      "Epoch [171/500], Loss: 0.6939853289251317\n",
      "Epoch [172/500], Loss: 0.6939853289251317\n",
      "Epoch [173/500], Loss: 0.6939853289251317\n",
      "Epoch [174/500], Loss: 0.6939853289251317\n",
      "Epoch [175/500], Loss: 0.6939853289251317\n",
      "Epoch [176/500], Loss: 0.6939853289251317\n",
      "Epoch [177/500], Loss: 0.6939853289251317\n",
      "Epoch [178/500], Loss: 0.6939853289251317\n",
      "Epoch [179/500], Loss: 0.6939853289251317\n",
      "Epoch [180/500], Loss: 0.6939853289251317\n",
      "Epoch [181/500], Loss: 0.6939853289251317\n",
      "Epoch [182/500], Loss: 0.6939853289251317\n",
      "Epoch [183/500], Loss: 0.6939853289251317\n",
      "Epoch [184/500], Loss: 0.6939853289251317\n",
      "Epoch [185/500], Loss: 0.6939853289251317\n",
      "Epoch [186/500], Loss: 0.6939853289251317\n",
      "Epoch [187/500], Loss: 0.6939853289251317\n",
      "Epoch [188/500], Loss: 0.6939853289251317\n",
      "Epoch [189/500], Loss: 0.6939853289251317\n",
      "Epoch [190/500], Loss: 0.6939853289251317\n",
      "Epoch [191/500], Loss: 0.6939853289251317\n",
      "Epoch [192/500], Loss: 0.6939853289251317\n",
      "Epoch [193/500], Loss: 0.6939853289251317\n",
      "Epoch [194/500], Loss: 0.6939853289251317\n",
      "Epoch [195/500], Loss: 0.6939853289251317\n",
      "Epoch [196/500], Loss: 0.6939853289251317\n",
      "Epoch [197/500], Loss: 0.6939853289251317\n",
      "Epoch [198/500], Loss: 0.6939853289251317\n",
      "Epoch [199/500], Loss: 0.6939853289251317\n",
      "Epoch [200/500], Loss: 0.6939853289251317\n",
      "Epoch [201/500], Loss: 0.6939853289251317\n",
      "Epoch [202/500], Loss: 0.6939853289251317\n",
      "Epoch [203/500], Loss: 0.6939853289251317\n",
      "Epoch [204/500], Loss: 0.6939853289251317\n",
      "Epoch [205/500], Loss: 0.6939853289251317\n",
      "Epoch [206/500], Loss: 0.6939853289251317\n",
      "Epoch [207/500], Loss: 0.6939853289251317\n",
      "Epoch [208/500], Loss: 0.6939853289251317\n",
      "Epoch [209/500], Loss: 0.6939853289251317\n",
      "Epoch [210/500], Loss: 0.6939853289251317\n",
      "Epoch [211/500], Loss: 0.6939853289251317\n",
      "Epoch [212/500], Loss: 0.6939853289251317\n",
      "Epoch [213/500], Loss: 0.6939853289251317\n",
      "Epoch [214/500], Loss: 0.6939853289251317\n",
      "Epoch [215/500], Loss: 0.6939853289251317\n",
      "Epoch [216/500], Loss: 0.6939853289251317\n",
      "Epoch [217/500], Loss: 0.6939853289251317\n",
      "Epoch [218/500], Loss: 0.6939853289251317\n",
      "Epoch [219/500], Loss: 0.6939853289251317\n",
      "Epoch [220/500], Loss: 0.6939853289251317\n",
      "Epoch [221/500], Loss: 0.6939853289251317\n",
      "Epoch [222/500], Loss: 0.6939853289251317\n",
      "Epoch [223/500], Loss: 0.6939853289251317\n",
      "Epoch [224/500], Loss: 0.6939853289251317\n",
      "Epoch [225/500], Loss: 0.6939853289251317\n",
      "Epoch [226/500], Loss: 0.6939853289251317\n",
      "Epoch [227/500], Loss: 0.6939853289251317\n",
      "Epoch [228/500], Loss: 0.6939853289251317\n",
      "Epoch [229/500], Loss: 0.6939853289251317\n",
      "Epoch [230/500], Loss: 0.6939853289251317\n",
      "Epoch [231/500], Loss: 0.6939853289251317\n",
      "Epoch [232/500], Loss: 0.6939853289251317\n",
      "Epoch [233/500], Loss: 0.6939853289251317\n",
      "Epoch [234/500], Loss: 0.6939853289251317\n",
      "Epoch [235/500], Loss: 0.6939853289251317\n",
      "Epoch [236/500], Loss: 0.6939853289251317\n",
      "Epoch [237/500], Loss: 0.6939853289251317\n",
      "Epoch [238/500], Loss: 0.6939853289251317\n",
      "Epoch [239/500], Loss: 0.6939853289251317\n",
      "Epoch [240/500], Loss: 0.6939853289251317\n",
      "Epoch [241/500], Loss: 0.6939853289251317\n",
      "Epoch [242/500], Loss: 0.6939853289251317\n",
      "Epoch [243/500], Loss: 0.6939853289251317\n",
      "Epoch [244/500], Loss: 0.6939853289251317\n",
      "Epoch [245/500], Loss: 0.6939853289251317\n",
      "Epoch [246/500], Loss: 0.6939853289251317\n",
      "Epoch [247/500], Loss: 0.6939853289251317\n",
      "Epoch [248/500], Loss: 0.6939853289251317\n",
      "Epoch [249/500], Loss: 0.6939853289251317\n",
      "Epoch [250/500], Loss: 0.6939853289251317\n",
      "Epoch [251/500], Loss: 0.6939853289251317\n",
      "Epoch [252/500], Loss: 0.6939853289251317\n",
      "Epoch [253/500], Loss: 0.6939853289251317\n",
      "Epoch [254/500], Loss: 0.6939853289251317\n",
      "Epoch [255/500], Loss: 0.6939853289251317\n",
      "Epoch [256/500], Loss: 0.6939853289251317\n",
      "Epoch [257/500], Loss: 0.6939853289251317\n",
      "Epoch [258/500], Loss: 0.6939853289251317\n",
      "Epoch [259/500], Loss: 0.6939853289251317\n",
      "Epoch [260/500], Loss: 0.6939853289251317\n",
      "Epoch [261/500], Loss: 0.6939853289251317\n",
      "Epoch [262/500], Loss: 0.6939853289251317\n",
      "Epoch [263/500], Loss: 0.6939853289251317\n",
      "Epoch [264/500], Loss: 0.6939853289251317\n",
      "Epoch [265/500], Loss: 0.6939853289251317\n",
      "Epoch [266/500], Loss: 0.6939853289251317\n",
      "Epoch [267/500], Loss: 0.6939853289251317\n",
      "Epoch [268/500], Loss: 0.6939853289251317\n",
      "Epoch [269/500], Loss: 0.6939853289251317\n",
      "Epoch [270/500], Loss: 0.6939853289251317\n",
      "Epoch [271/500], Loss: 0.6939853289251317\n",
      "Epoch [272/500], Loss: 0.6939853289251317\n",
      "Epoch [273/500], Loss: 0.6939853289251317\n",
      "Epoch [274/500], Loss: 0.6939853289251317\n",
      "Epoch [275/500], Loss: 0.6939853289251317\n",
      "Epoch [276/500], Loss: 0.6939853289251317\n",
      "Epoch [277/500], Loss: 0.6939853289251317\n",
      "Epoch [278/500], Loss: 0.6939853289251317\n",
      "Epoch [279/500], Loss: 0.6939853289251317\n",
      "Epoch [280/500], Loss: 0.6939853289251317\n",
      "Epoch [281/500], Loss: 0.6939853289251317\n",
      "Epoch [282/500], Loss: 0.6939853289251317\n",
      "Epoch [283/500], Loss: 0.6939853289251317\n",
      "Epoch [284/500], Loss: 0.6939853289251317\n",
      "Epoch [285/500], Loss: 0.6939853289251317\n",
      "Epoch [286/500], Loss: 0.6939853289251317\n",
      "Epoch [287/500], Loss: 0.6939853289251317\n",
      "Epoch [288/500], Loss: 0.6939853289251317\n",
      "Epoch [289/500], Loss: 0.6939853289251317\n",
      "Epoch [290/500], Loss: 0.6939853289251317\n",
      "Epoch [291/500], Loss: 0.6939853289251317\n",
      "Epoch [292/500], Loss: 0.6939853289251317\n",
      "Epoch [293/500], Loss: 0.6939853289251317\n",
      "Epoch [294/500], Loss: 0.6939853289251317\n",
      "Epoch [295/500], Loss: 0.6939853289251317\n",
      "Epoch [296/500], Loss: 0.6939853289251317\n",
      "Epoch [297/500], Loss: 0.6939853289251317\n",
      "Epoch [298/500], Loss: 0.6939853289251317\n",
      "Epoch [299/500], Loss: 0.6939853289251317\n",
      "Epoch [300/500], Loss: 0.6939853289251317\n",
      "Epoch [301/500], Loss: 0.6939853289251317\n",
      "Epoch [302/500], Loss: 0.6939853289251317\n",
      "Epoch [303/500], Loss: 0.6939853289251317\n",
      "Epoch [304/500], Loss: 0.6939853289251317\n",
      "Epoch [305/500], Loss: 0.6939853289251317\n",
      "Epoch [306/500], Loss: 0.6939853289251317\n",
      "Epoch [307/500], Loss: 0.6939853289251317\n",
      "Epoch [308/500], Loss: 0.6939853289251317\n",
      "Epoch [309/500], Loss: 0.6939853289251317\n",
      "Epoch [310/500], Loss: 0.6939853289251317\n",
      "Epoch [311/500], Loss: 0.6939853289251317\n",
      "Epoch [312/500], Loss: 0.6939853289251317\n",
      "Epoch [313/500], Loss: 0.6939853289251317\n",
      "Epoch [314/500], Loss: 0.6939853289251317\n",
      "Epoch [315/500], Loss: 0.6939853289251317\n",
      "Epoch [316/500], Loss: 0.6939853289251317\n",
      "Epoch [317/500], Loss: 0.6939853289251317\n",
      "Epoch [318/500], Loss: 0.6939853289251317\n",
      "Epoch [319/500], Loss: 0.6939853289251317\n",
      "Epoch [320/500], Loss: 0.6939853289251317\n",
      "Epoch [321/500], Loss: 0.6939853289251317\n",
      "Epoch [322/500], Loss: 0.6939853289251317\n",
      "Epoch [323/500], Loss: 0.6939853289251317\n",
      "Epoch [324/500], Loss: 0.6939853289251317\n",
      "Epoch [325/500], Loss: 0.6939853289251317\n",
      "Epoch [326/500], Loss: 0.6939853289251317\n",
      "Epoch [327/500], Loss: 0.6939853289251317\n",
      "Epoch [328/500], Loss: 0.6939853289251317\n",
      "Epoch [329/500], Loss: 0.6939853289251317\n",
      "Epoch [330/500], Loss: 0.6939853289251317\n",
      "Epoch [331/500], Loss: 0.6939853289251317\n",
      "Epoch [332/500], Loss: 0.6939853289251317\n",
      "Epoch [333/500], Loss: 0.6939853289251317\n",
      "Epoch [334/500], Loss: 0.6939853289251317\n",
      "Epoch [335/500], Loss: 0.6939853289251317\n",
      "Epoch [336/500], Loss: 0.6939853289251317\n",
      "Epoch [337/500], Loss: 0.6939853289251317\n",
      "Epoch [338/500], Loss: 0.6939853289251317\n",
      "Epoch [339/500], Loss: 0.6939853289251317\n",
      "Epoch [340/500], Loss: 0.6939853289251317\n",
      "Epoch [341/500], Loss: 0.6939853289251317\n",
      "Epoch [342/500], Loss: 0.6939853289251317\n",
      "Epoch [343/500], Loss: 0.6939853289251317\n",
      "Epoch [344/500], Loss: 0.6939853289251317\n",
      "Epoch [345/500], Loss: 0.6939853289251317\n",
      "Epoch [346/500], Loss: 0.6939853289251317\n",
      "Epoch [347/500], Loss: 0.6939853289251317\n",
      "Epoch [348/500], Loss: 0.6939853289251317\n",
      "Epoch [349/500], Loss: 0.6939853289251317\n",
      "Epoch [350/500], Loss: 0.6939853289251317\n",
      "Epoch [351/500], Loss: 0.6939853289251317\n",
      "Epoch [352/500], Loss: 0.6939853289251317\n",
      "Epoch [353/500], Loss: 0.6939853289251317\n",
      "Epoch [354/500], Loss: 0.6939853289251317\n",
      "Epoch [355/500], Loss: 0.6939853289251317\n",
      "Epoch [356/500], Loss: 0.6939853289251317\n",
      "Epoch [357/500], Loss: 0.6939853289251317\n",
      "Epoch [358/500], Loss: 0.6939853289251317\n",
      "Epoch [359/500], Loss: 0.6939853289251317\n",
      "Epoch [360/500], Loss: 0.6939853289251317\n",
      "Epoch [361/500], Loss: 0.6939853289251317\n",
      "Epoch [362/500], Loss: 0.6939853289251317\n",
      "Epoch [363/500], Loss: 0.6939853289251317\n",
      "Epoch [364/500], Loss: 0.6939853289251317\n",
      "Epoch [365/500], Loss: 0.6939853289251317\n",
      "Epoch [366/500], Loss: 0.6939853289251317\n",
      "Epoch [367/500], Loss: 0.6939853289251317\n",
      "Epoch [368/500], Loss: 0.6939853289251317\n",
      "Epoch [369/500], Loss: 0.6939853289251317\n",
      "Epoch [370/500], Loss: 0.6939853289251317\n",
      "Epoch [371/500], Loss: 0.6939853289251317\n",
      "Epoch [372/500], Loss: 0.6939853289251317\n",
      "Epoch [373/500], Loss: 0.6939853289251317\n",
      "Epoch [374/500], Loss: 0.6939853289251317\n",
      "Epoch [375/500], Loss: 0.6939853289251317\n",
      "Epoch [376/500], Loss: 0.6939853289251317\n",
      "Epoch [377/500], Loss: 0.6939853289251317\n",
      "Epoch [378/500], Loss: 0.6939853289251317\n",
      "Epoch [379/500], Loss: 0.6939853289251317\n",
      "Epoch [380/500], Loss: 0.6939853289251317\n",
      "Epoch [381/500], Loss: 0.6939853289251317\n",
      "Epoch [382/500], Loss: 0.6939853289251317\n",
      "Epoch [383/500], Loss: 0.6939853289251317\n",
      "Epoch [384/500], Loss: 0.6939853289251317\n",
      "Epoch [385/500], Loss: 0.6939853289251317\n",
      "Epoch [386/500], Loss: 0.6939853289251317\n",
      "Epoch [387/500], Loss: 0.6939853289251317\n",
      "Epoch [388/500], Loss: 0.6939853289251317\n",
      "Epoch [389/500], Loss: 0.6939853289251317\n",
      "Epoch [390/500], Loss: 0.6939853289251317\n",
      "Epoch [391/500], Loss: 0.6939853289251317\n",
      "Epoch [392/500], Loss: 0.6939853289251317\n",
      "Epoch [393/500], Loss: 0.6939853289251317\n",
      "Epoch [394/500], Loss: 0.6939853289251317\n",
      "Epoch [395/500], Loss: 0.6939853289251317\n",
      "Epoch [396/500], Loss: 0.6939853289251317\n",
      "Epoch [397/500], Loss: 0.6939853289251317\n",
      "Epoch [398/500], Loss: 0.6939853289251317\n",
      "Epoch [399/500], Loss: 0.6939853289251317\n",
      "Epoch [400/500], Loss: 0.6939853289251317\n",
      "Epoch [401/500], Loss: 0.6939853289251317\n",
      "Epoch [402/500], Loss: 0.6939853289251317\n",
      "Epoch [403/500], Loss: 0.6939853289251317\n",
      "Epoch [404/500], Loss: 0.6939853289251317\n",
      "Epoch [405/500], Loss: 0.6939853289251317\n",
      "Epoch [406/500], Loss: 0.6939853289251317\n",
      "Epoch [407/500], Loss: 0.6939853289251317\n",
      "Epoch [408/500], Loss: 0.6939853289251317\n",
      "Epoch [409/500], Loss: 0.6939853289251317\n",
      "Epoch [410/500], Loss: 0.6939853289251317\n",
      "Epoch [411/500], Loss: 0.6939853289251317\n",
      "Epoch [412/500], Loss: 0.6939853289251317\n",
      "Epoch [413/500], Loss: 0.6939853289251317\n",
      "Epoch [414/500], Loss: 0.6939853289251317\n",
      "Epoch [415/500], Loss: 0.6939853289251317\n",
      "Epoch [416/500], Loss: 0.6939853289251317\n",
      "Epoch [417/500], Loss: 0.6939853289251317\n",
      "Epoch [418/500], Loss: 0.6939853289251317\n",
      "Epoch [419/500], Loss: 0.6939853289251317\n",
      "Epoch [420/500], Loss: 0.6939853289251317\n",
      "Epoch [421/500], Loss: 0.6939853289251317\n",
      "Epoch [422/500], Loss: 0.6939853289251317\n",
      "Epoch [423/500], Loss: 0.6939853289251317\n",
      "Epoch [424/500], Loss: 0.6939853289251317\n",
      "Epoch [425/500], Loss: 0.6939853289251317\n",
      "Epoch [426/500], Loss: 0.6939853289251317\n",
      "Epoch [427/500], Loss: 0.6939853289251317\n",
      "Epoch [428/500], Loss: 0.6939853289251317\n",
      "Epoch [429/500], Loss: 0.6939853289251317\n",
      "Epoch [430/500], Loss: 0.6939853289251317\n",
      "Epoch [431/500], Loss: 0.6939853289251317\n",
      "Epoch [432/500], Loss: 0.6939853289251317\n",
      "Epoch [433/500], Loss: 0.6939853289251317\n",
      "Epoch [434/500], Loss: 0.6939853289251317\n",
      "Epoch [435/500], Loss: 0.6939853289251317\n",
      "Epoch [436/500], Loss: 0.6939853289251317\n",
      "Epoch [437/500], Loss: 0.6939853289251317\n",
      "Epoch [438/500], Loss: 0.6939853289251317\n",
      "Epoch [439/500], Loss: 0.6939853289251317\n",
      "Epoch [440/500], Loss: 0.6939853289251317\n",
      "Epoch [441/500], Loss: 0.6939853289251317\n",
      "Epoch [442/500], Loss: 0.6939853289251317\n",
      "Epoch [443/500], Loss: 0.6939853289251317\n",
      "Epoch [444/500], Loss: 0.6939853289251317\n",
      "Epoch [445/500], Loss: 0.6939853289251317\n",
      "Epoch [446/500], Loss: 0.6939853289251317\n",
      "Epoch [447/500], Loss: 0.6939853289251317\n",
      "Epoch [448/500], Loss: 0.6939853289251317\n",
      "Epoch [449/500], Loss: 0.6939853289251317\n",
      "Epoch [450/500], Loss: 0.6939853289251317\n",
      "Epoch [451/500], Loss: 0.6939853289251317\n",
      "Epoch [452/500], Loss: 0.6939853289251317\n",
      "Epoch [453/500], Loss: 0.6939853289251317\n",
      "Epoch [454/500], Loss: 0.6939853289251317\n",
      "Epoch [455/500], Loss: 0.6939853289251317\n",
      "Epoch [456/500], Loss: 0.6939853289251317\n",
      "Epoch [457/500], Loss: 0.6939853289251317\n",
      "Epoch [458/500], Loss: 0.6939853289251317\n",
      "Epoch [459/500], Loss: 0.6939853289251317\n",
      "Epoch [460/500], Loss: 0.6939853289251317\n",
      "Epoch [461/500], Loss: 0.6939853289251317\n",
      "Epoch [462/500], Loss: 0.6939853289251317\n",
      "Epoch [463/500], Loss: 0.6939853289251317\n",
      "Epoch [464/500], Loss: 0.6939853289251317\n",
      "Epoch [465/500], Loss: 0.6939853289251317\n",
      "Epoch [466/500], Loss: 0.6939853289251317\n",
      "Epoch [467/500], Loss: 0.6939853289251317\n",
      "Epoch [468/500], Loss: 0.6939853289251317\n",
      "Epoch [469/500], Loss: 0.6939853289251317\n",
      "Epoch [470/500], Loss: 0.6939853289251317\n",
      "Epoch [471/500], Loss: 0.6939853289251317\n",
      "Epoch [472/500], Loss: 0.6939853289251317\n",
      "Epoch [473/500], Loss: 0.6939853289251317\n",
      "Epoch [474/500], Loss: 0.6939853289251317\n",
      "Epoch [475/500], Loss: 0.6939853289251317\n",
      "Epoch [476/500], Loss: 0.6939853289251317\n",
      "Epoch [477/500], Loss: 0.6939853289251317\n",
      "Epoch [478/500], Loss: 0.6939853289251317\n",
      "Epoch [479/500], Loss: 0.6939853289251317\n",
      "Epoch [480/500], Loss: 0.6939853289251317\n",
      "Epoch [481/500], Loss: 0.6939853289251317\n",
      "Epoch [482/500], Loss: 0.6939853289251317\n",
      "Epoch [483/500], Loss: 0.6939853289251317\n",
      "Epoch [484/500], Loss: 0.6939853289251317\n",
      "Epoch [485/500], Loss: 0.6939853289251317\n",
      "Epoch [486/500], Loss: 0.6939853289251317\n",
      "Epoch [487/500], Loss: 0.6939853289251317\n",
      "Epoch [488/500], Loss: 0.6939853289251317\n",
      "Epoch [489/500], Loss: 0.6939853289251317\n",
      "Epoch [490/500], Loss: 0.6939853289251317\n",
      "Epoch [491/500], Loss: 0.6939853289251317\n",
      "Epoch [492/500], Loss: 0.6939853289251317\n",
      "Epoch [493/500], Loss: 0.6939853289251317\n",
      "Epoch [494/500], Loss: 0.6939853289251317\n",
      "Epoch [495/500], Loss: 0.6939853289251317\n",
      "Epoch [496/500], Loss: 0.6939853289251317\n",
      "Epoch [497/500], Loss: 0.6939853289251317\n",
      "Epoch [498/500], Loss: 0.6939853289251317\n",
      "Epoch [499/500], Loss: 0.6939853289251317\n",
      "Epoch [500/500], Loss: 0.6939853289251317\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, device, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Save the trained model parameters\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8605740181268882\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Step 2: Initialize lists to store predictions and true labels\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "# Step 3: Iterate through the test DataLoader\n",
    "with torch.no_grad():  # No need to calculate gradients during inference\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Step 4: Perform inference\n",
    "        outputs = model(inputs)\n",
    "        predictions = torch.round(outputs)  # For binary classification with sigmoid activation\n",
    "\n",
    "        # Step 5: Store predictions and true labels\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Step 6: Calculate accuracy\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Step 7: Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=data['DIABETE3'].unique())  # Adjust display_labels if needed\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
